{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models_dict = {\n",
    "    \"MobileNetV3S\": models.mobilenet_v3_small(weights=None),\n",
    "    \"ShuffleNetV2\": models.shufflenet_v2_x1_0(weights=None),\n",
    "    \"MobileNetV2\": models.mobilenet_v2(weights=None),\n",
    "    \"ResNet18\": models.resnet18(weights=None),\n",
    "    \"SqueezeNet\": models.squeezenet1_0(weights=None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and evaluation\n",
    "dataset_path = \"./dataset\"\n",
    "augment_data = False\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentations\n",
    "augmentations = {\n",
    "    \"brightness\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(brightness=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "    \"contrast\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(contrast=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "    \"saturation\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(saturation=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "    \"hue\": transforms.Compose(\n",
    "        [\n",
    "            transforms.ColorJitter(hue=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage(),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\n",
    "    d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))\n",
    "]\n",
    "\n",
    "if augment_data:\n",
    "    for dir in dirs:\n",
    "        files = os.listdir(os.path.join(dataset_path, dir))\n",
    "\n",
    "        for file_name in tqdm(files, desc=f\"Processing {dir}\"):\n",
    "            file_path = os.path.join(dataset_path, dir, file_name)\n",
    "            photo_id = re.search(r\"\\d+\", file_name).group()\n",
    "\n",
    "            if file_name != f\"{photo_id}.jpg\":\n",
    "                continue\n",
    "\n",
    "            image = Image.open(file_path).convert(\"RGB\")\n",
    "\n",
    "            for name, augmentation in augmentations.items():\n",
    "                augmented_image = augmentation(image)\n",
    "                augmented_image = np.array(augmented_image)\n",
    "                augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "                save_path = os.path.join(dataset_path, dir, f\"{photo_id}_{name}.jpg\")\n",
    "                cv2.imwrite(save_path, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class JetBotDataset(Dataset):\n",
    "    def __init__(self, target_map, transform=None):\n",
    "        self.target_map = target_map\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.target_map[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(path, dirs):\n",
    "    result = []\n",
    "    for dir in dirs:\n",
    "        labels = pd.read_csv(\n",
    "            f\"{path}/{dir}.csv\", header=None, index_col=0, names=[\"speed\", \"turn\"]\n",
    "        )\n",
    "        for file_name in os.listdir(os.path.join(path, dir)):\n",
    "            file_path = os.path.join(path, dir, file_name)\n",
    "            photo_id = int(re.search(r\"\\d+\", file_name).group())\n",
    "            if photo_id in labels.index:\n",
    "                target = labels.loc[photo_id]\n",
    "                result.append((file_path, (target[\"speed\"], target[\"turn\"])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and transformation\n",
    "target_map = get_target(dataset_path, dirs)\n",
    "train_data, test_data = train_test_split(target_map, test_size=0.2, random_state=42)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = JetBotDataset(train_data, transform=transform)\n",
    "test_dataset = JetBotDataset(test_data, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify models for regression\n",
    "def modify_model(model, model_name):\n",
    "    if model_name == \"SqueezeNet\":\n",
    "        model.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
    "    elif model_name == \"MobileNetV2\":\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "    elif model_name == \"ResNet18\":\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    elif model_name == \"MobileNetV3S\":\n",
    "        model.classifier[3] = nn.Linear(model.classifier[3].in_features, 2)\n",
    "    elif model_name == \"ShuffleNetV2\":\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs):\n",
    "    scaler = GradScaler()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\" Epoch {epoch}/{num_epochs - 1}\")\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for inputs, targets in dataloaders[phase]:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                if phase == \"train\":\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print(f\"  {phase} loss: {epoch_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MobileNetV3S...\n",
      " Epoch 0/24\n",
      "  train loss: 0.1152\n",
      "  val loss: 0.2244\n",
      " Epoch 1/24\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "for model_name in models_dict:\n",
    "    model = modify_model(models_dict[model_name], model_name).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    dataloaders = {\"train\": train_loader, \"val\": test_loader}\n",
    "    print(f\"Training {model_name}...\")\n",
    "    trained_model = train_model(\n",
    "        model, dataloaders, criterion, optimizer, num_epochs=num_epochs\n",
    "    )\n",
    "    torch.save(trained_model.state_dict(), f\"{model_name}_model.pth\")\n",
    "    print(f\"{model_name} training complete.\")\n",
    "\n",
    "    # Export model to ONNX\n",
    "    dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "    torch.onnx.export(\n",
    "        trained_model,\n",
    "        dummy_input,\n",
    "        f\"./models/{model_name}.onnx\",\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "    )\n",
    "    print(f\"{model_name} exported as ONNX.\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "jetbot-dl-model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
